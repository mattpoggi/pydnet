# Copyright UCL Business plc 2017. Patent Pending. All rights reserved.
#
# The MonoDepth Software is licensed under the terms of the UCLB ACP-A licence
# which allows for non-commercial use only, the full terms of which are made
# available in the LICENSE file.
#
# For any other use of the software not covered by the UCLB ACP-A Licence,
# please contact info@uclb.com

"""Fully convolutional model for monocular depth estimation
    by Clement Godard, Oisin Mac Aodha and Gabriel J. Brostow
    http://visual.cs.ucl.ac.uk/pubs/monoDepth/
"""

"""
    The original source code (https://github.com/mrharicot/monodepth/blob/master/monodepth_model.py)
    has been modified to train pydnet model (https://github.com/mattpoggi/pydnet) for research purpose only.
"""


from collections import namedtuple
import numpy as np
import tensorflow as tf
import tensorflow.contrib.slim as slim
from bilinear_sampler import *
from pydnet import *
monodepth_parameters = namedtuple('parameters',
                                  'encoder, '
                                  'height, width, '
                                  'batch_size, '
                                  'num_threads, '
                                  'num_epochs, '
                                  'do_stereo, '
                                  'wrap_mode, '
                                  'use_deconv, '
                                  'alpha_image_loss, '
                                  'disp_gradient_loss_weight, '
                                  'lr_loss_weight, '
                                  'full_summary')


class MonodepthModel(object):
    """monodepth model"""

    def __init__(self, params, mode, left, right,
                 reuse_variables=None, model_index=0):
        self.params = params
        self.mode = mode
        self.left = left
        self.right = right
        self.model_collection = ['model_' + str(model_index)]

        self.reuse_variables = reuse_variables
        self.build_model()
        self.build_outputs()

        if self.mode == 'test':
            return

        self.build_losses()
        self.build_summaries()

    def gradient_x(self, img):
        gx = img[:, :, :-1, :] - img[:, :, 1:, :]
        return gx

    def gradient_y(self, img):
        gy = img[:, :-1, :, :] - img[:, 1:, :, :]
        return gy

    def upsample_nn(self, x, ratio):
        s = tf.shape(input=x)
        h = s[1]
        w = s[2]
        return tf.image.resize(
            x, [h * ratio, w * ratio], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)

    def scale_pyramid(self, img, num_scales):
        scaled_imgs = []  # don't need full res images
        s = tf.shape(input=img)
        h = s[1]
        w = s[2]
        for i in range(num_scales - 1):
            ratio = 2 ** (i + 1)
            nh = h / ratio
            nw = w / ratio
            scaled_imgs.append(
                tf.cast(
                    tf.image.resize(
                        img, [
                            nh, nw], method=tf.image.ResizeMethod.AREA), tf.float32))
        return scaled_imgs

    def generate_image_left(self, img, disp):
        return tf.cast(bilinear_sampler_1d_h(
            tf.cast(img, tf.float32), tf.cast(-disp, tf.float32)), tf.float32)

    def generate_image_right(self, img, disp):
        return tf.cast(bilinear_sampler_1d_h(
            tf.cast(img, tf.float32), tf.cast(disp, tf.float32)), tf.float32)

    def SSIM(self, x, y):
        C1 = 0.01 ** 2
        C2 = 0.03 ** 2

        mu_x = slim.avg_pool2d(x, 3, 1, 'VALID')
        mu_y = slim.avg_pool2d(y, 3, 1, 'VALID')

        sigma_x = slim.avg_pool2d(x ** 2, 3, 1, 'VALID') - mu_x ** 2
        sigma_y = slim.avg_pool2d(y ** 2, 3, 1, 'VALID') - mu_y ** 2
        sigma_xy = slim.avg_pool2d(x * y, 3, 1, 'VALID') - mu_x * mu_y

        SSIM_n = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)
        SSIM_d = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)

        SSIM = SSIM_n / SSIM_d

        return tf.clip_by_value((1 - SSIM) / 2, 0, 1)

    def get_disparity_smoothness(self, disp, pyramid):
        disp_gradients_x = [self.gradient_x(d) for d in disp]
        disp_gradients_y = [self.gradient_y(d) for d in disp]

        image_gradients_x = [self.gradient_x(img) for img in pyramid]
        image_gradients_y = [self.gradient_y(img) for img in pyramid]

        weights_x = [tf.exp(-tf.reduce_mean(input_tensor=tf.abs(g),
                            axis=3, keepdims=True)) for g in image_gradients_x]
        weights_y = [tf.exp(-tf.reduce_mean(input_tensor=tf.abs(g),
                            axis=3, keepdims=True)) for g in image_gradients_y]

        scales = 6
        smoothness_x = [disp_gradients_x[i] * weights_x[i]
                        for i in range(scales)]
        smoothness_y = [disp_gradients_y[i] * weights_y[i]
                        for i in range(scales)]
        return smoothness_x + smoothness_y

    def build_model(self):
        with slim.arg_scope([slim.conv2d, slim.conv2d_transpose], activation_fn=tf.nn.elu):
            with tf.compat.v1.variable_scope('model', reuse=self.reuse_variables):

                self.left_pyramid = self.scale_pyramid(self.left, 4)
                if self.mode == 'train':
                    self.right_pyramid = self.scale_pyramid(self.right, 4)

                if self.params.do_stereo:
                    self.model_input = tf.concat([self.left, self.right], 3)
                else:
                    self.model_input = self.left

                # build model
                placeholders = {"im0": self.model_input}
                model = pydnet(placeholders)
                self.disp1 = model.results[0]
                self.disp2 = model.disp2
                self.disp3 = model.disp3
                self.disp4 = model.disp4
                self.disp5 = model.disp5
                self.disp6 = model.disp6
                self.disp7 = model.disp7

    def build_outputs(self):
        self.build_output()

        if self.mode == 'test':
            return
        self.finish_build_outputs()

    def build_output(self):
        # STORE DISPARITIES
        self.num_scale = 6
        with tf.compat.v1.variable_scope('disparities'):
            self.disp_est = [
                self.disp2,
                self.disp3,
                self.disp4,
                self.disp5,
                self.disp6,
                self.disp7]
            self.disp_left_est = [tf.expand_dims(
                d[:, :, :, 0], 3) for d in self.disp_est]
            self.disp_right_est = [tf.expand_dims(
                d[:, :, :, 1], 3) for d in self.disp_est]
        self.left_pyramid = self.scale_pyramid(self.left, 7)
        if self.mode == 'train':
            self.right_pyramid = self.scale_pyramid(self.right, 7)

    def finish_build_outputs(self):
        # GENERATE IMAGES
        with tf.compat.v1.variable_scope('images'):
            self.left_est = [
                self.generate_image_left(
                    self.right_pyramid[i],
                    self.disp_left_est[i]) for i in range(
                    self.num_scale)]
            self.right_est = [
                self.generate_image_right(
                    self.left_pyramid[i],
                    self.disp_right_est[i]) for i in range(
                    self.num_scale)]

        # LR CONSISTENCY
        with tf.compat.v1.variable_scope('left-right'):
            self.right_to_left_disp = [
                self.generate_image_left(
                    self.disp_right_est[i],
                    self.disp_left_est[i]) for i in range(
                    self.num_scale)]
            self.left_to_right_disp = [
                self.generate_image_right(
                    self.disp_left_est[i],
                    self.disp_right_est[i]) for i in range(
                    self.num_scale)]

        # DISPARITY SMOOTHNESS
        with tf.compat.v1.variable_scope('smoothness'):
            self.disp_left_smoothness = self.get_disparity_smoothness(
                self.disp_left_est, self.left_pyramid)
            self.disp_right_smoothness = self.get_disparity_smoothness(
                self.disp_right_est, self.right_pyramid)

    def build_losses(self):
        with tf.compat.v1.variable_scope('losses', reuse=self.reuse_variables):
            # IMAGE RECONSTRUCTION
            # L1
            self.l1_left = [
                tf.abs(
                    self.left_est[i] -
                    self.left_pyramid[i]) for i in range(
                    self.num_scale)]
            self.l1_reconstruction_loss_left = [
                tf.reduce_mean(input_tensor=l) for l in self.l1_left]
            self.l1_right = [
                tf.abs(
                    self.right_est[i] -
                    self.right_pyramid[i]) for i in range(
                    self.num_scale)]
            self.l1_reconstruction_loss_right = [
                tf.reduce_mean(input_tensor=l) for l in self.l1_right]

            # SSIM
            self.ssim_left = [
                self.SSIM(
                    self.left_est[i],
                    self.left_pyramid[i]) for i in range(
                    self.num_scale)]
            self.ssim_loss_left = [
                tf.reduce_mean(
                    input_tensor=s) for s in self.ssim_left]
            self.ssim_right = [
                self.SSIM(
                    self.right_est[i],
                    self.right_pyramid[i]) for i in range(
                    self.num_scale)]
            self.ssim_loss_right = [
                tf.reduce_mean(
                    input_tensor=s) for s in self.ssim_right]

            # WEIGTHED SUM
            self.image_loss_right = [
                self.params.alpha_image_loss *
                self.ssim_loss_right[i] +
                (
                    1 -
                    self.params.alpha_image_loss) *
                self.l1_reconstruction_loss_right[i] for i in range(
                    self.num_scale)]
            self.image_loss_left = [
                self.params.alpha_image_loss *
                self.ssim_loss_left[i] +
                (
                    1 -
                    self.params.alpha_image_loss) *
                self.l1_reconstruction_loss_left[i] for i in range(
                    self.num_scale)]
            self.image_loss = tf.add_n(
                self.image_loss_left + self.image_loss_right)

            # DISPARITY SMOOTHNESS
            self.disp_left_loss = [tf.reduce_mean(input_tensor=tf.abs(
                self.disp_left_smoothness[i])) / 2 ** i for i in range(self.num_scale)]
            self.disp_right_loss = [tf.reduce_mean(input_tensor=tf.abs(
                self.disp_right_smoothness[i])) / 2 ** i for i in range(self.num_scale)]
            self.disp_gradient_loss = tf.add_n(
                self.disp_left_loss + self.disp_right_loss)

            # LR CONSISTENCY
            self.lr_left_loss = [
                tf.reduce_mean(
                    input_tensor=tf.abs(
                        self.right_to_left_disp[i] -
                        self.disp_left_est[i])) for i in range(
                    self.num_scale)]
            self.lr_right_loss = [
                tf.reduce_mean(
                    input_tensor=tf.abs(
                        self.left_to_right_disp[i] -
                        self.disp_right_est[i])) for i in range(
                    self.num_scale)]
            self.lr_loss = tf.add_n(self.lr_left_loss + self.lr_right_loss)

            # TOTAL LOSS
            self.total_loss = self.image_loss + self.params.disp_gradient_loss_weight * \
                self.disp_gradient_loss + self.params.lr_loss_weight * self.lr_loss

    def build_summaries(self):
        # SUMMARIES
        with tf.device('/cpu:0'):
            for i in range(self.num_scale):
                tf.compat.v1.summary.scalar('ssim_loss_' + str(i + 1),
                                            self.ssim_loss_left[i] +
                                            self.ssim_loss_right[i],
                                            collections=self.model_collection)
                tf.compat.v1.summary.scalar(
                    'l1_loss_' +
                    str(
                        i +
                        1),
                    self.l1_reconstruction_loss_left[i] +
                    self.l1_reconstruction_loss_right[i],
                    collections=self.model_collection)
                tf.compat.v1.summary.scalar('image_loss_' + str(i + 1),
                                            self.image_loss_left[i] +
                                            self.image_loss_right[i],
                                            collections=self.model_collection)
                tf.compat.v1.summary.scalar(
                    'disp_gradient_loss_' + str(
                        i + 1),
                    self.disp_left_loss[i] + self.disp_right_loss[i],
                    collections=self.model_collection)
                tf.compat.v1.summary.scalar('lr_loss_' + str(i + 1),
                                            self.lr_left_loss[i] +
                                            self.lr_right_loss[i],
                                            collections=self.model_collection)
                tf.compat.v1.summary.image(
                    'disp_left_est_' + str(
                        i + 1),
                    self.disp_left_est[i],
                    max_outputs=1,
                    collections=self.model_collection)
                tf.compat.v1.summary.image(
                    'disp_right_est_' + str(
                        i + 1),
                    self.disp_right_est[i],
                    max_outputs=1,
                    collections=self.model_collection)

                if self.params.full_summary:
                    tf.compat.v1.summary.image(
                        'left_est_' + str(i + 1), self.left_est[i], max_outputs=1, collections=self.model_collection)
                    tf.compat.v1.summary.image(
                        'right_est_' + str(
                            i + 1),
                        self.right_est[i],
                        max_outputs=1,
                        collections=self.model_collection)
                    tf.compat.v1.summary.image(
                        'ssim_left_' + str(
                            i + 1),
                        self.ssim_left[i],
                        max_outputs=1,
                        collections=self.model_collection)
                    tf.compat.v1.summary.image(
                        'ssim_right_' + str(
                            i + 1),
                        self.ssim_right[i],
                        max_outputs=1,
                        collections=self.model_collection)
                    tf.compat.v1.summary.image(
                        'l1_left_' + str(i + 1), self.l1_left[i], max_outputs=1, collections=self.model_collection)
                    tf.compat.v1.summary.image(
                        'l1_right_' + str(i + 1), self.l1_right[i], max_outputs=1, collections=self.model_collection)

            if self.params.full_summary:
                tf.compat.v1.summary.image(
                    'left', self.left, max_outputs=1, collections=self.model_collection)
                tf.compat.v1.summary.image(
                    'right',
                    self.right,
                    max_outputs=1,
                    collections=self.model_collection)
